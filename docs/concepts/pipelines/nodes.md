# Node Types

## LLM
Uses an LLM to respond to the input.

## LLM Router
Routes the input to one of the linked nodes using an LLM. In this case, the LLM acts as a classifier using the prompt provided to classify an incoming message into a set of discrete categories that allow messages to be routed.

!!! info "Constrained outputs"

    Currently the LLM Router node does not enforce constrained outputs, however, in the very near future, they will. This will be accomplished using a strict `json_mode` (for supporting models) that ensure that the LLM only generates one of the valid classification labels.

The `outputs` listed by the node are the available classification labels. These should match the classification categories specified in your prompt. They can be adjusted through the `Advanced` settings for the node. The top output, which is prepended by a blue `*` is the default label. In the event that the LLM generates a response outside of the specified `outputs`, the route with the default label will be taken.

!!! info "Best practices for configuring a LLM Router"

    It is advisable to use the [Node history mode](history.md#node) for an LLM Router to avoid unintentionally supplying few-shot examples to the node with an incorrect output format.

## Static Router
Routes the input to a linked node using the participant data or temporary state of the pipeline.

## Assistant
Uses an OpenAI assistant to respond to the input.

## Python Node
The Python node allows the bot builder to execute custom Python code to perform logic, data processing, or other tasks.

All the code must be encapsulated in a `main` function, which takes the node input as a string and returns a string to pass to the next node.
The `main` function must also accept arbitrary keyword arguments to support future features. Here is an example of what the code might look like:

```python
def main(input, **kwargs) -> str:
    # Put your code here
    return input
```

The `input` parameter is a string that contains the input to the node. The return value of the function is a string that will be passed to the next node in the pipeline.

The `kwargs` parameter is currently unused, but it is included to support future features that may require additional arguments to be passed to the function (though it is required to be present in the function signature).

### Utility Functions

The Python node provides a set of utility functions that can be used to interact with the user's data and the pipeline state.

#### ::: python_node.get_participant_data
#### ::: python_node.set_participant_data
#### ::: python_node.get_temp_state_key
#### ::: python_node.set_temp_state_key

### Temporary State
The Python node can also access and modify the temporary state of the pipeline. The temporary state is a dictionary that is unique to each run of the pipeline (each new message from the user) and is not stored between sessions.

The temporary state can be accessed and modified using the [get_temp_state_key](#python_node.get_temp_state_key) and [set_temp_state_key](#python_node.set_temp_state_key) utility functions.

Temporary state contains the following keys by default. These keys can not be modified or deleted:

| Key           | Description                                                                  |
|---------------|------------------------------------------------------------------------------|
| `user_input`  | The message sent by the user                                                 |
| `outputs`     | The outputs generated by the previous node                                   |
| `attachments` | A list of attachments passed in by the user. See [Attachments](#attachments) |

In addition to these keys, the temporary state can also contain custom key-value pairs that can be set and accessed by the Python node and by the [Static Router](#static-router) node.

Here is an example of a temporary state dictionary:

```python
{
    "user_input": "Please help me with my problem",
    "outputs": {
        "Assistant": "I'm here to help! What can I do for you?"
    },
    "attachments": [
        Attachment(...),
    ],
    "my_custom_key": "my_custom_value",
}
```

### Attachments

Part of the temporary state is a list of attachments. Attachments are files that the user has uploaded to the bot. Each attachment has the following fields:

| Field                 | Description                                                           |
|-----------------------|-----------------------------------------------------------------------|
| `name`                | The name of the file                                                  |
| `size`                | The size of the file in bytes                                         |
| `content_type`        | The MIME type of the file                                             |
| `upload_to_assistant` | Whether the file should be uploaded to the assistant as an attachment |
| `read_bytes()`        | Reads the attachment content as bytes.                                |
| `read_text()`         | Reads the attachment content as text.                                 |

Here is an example of an attachment object:

```python
attachment = Attachment(
    name="proposal.pdf",
    size=1234,
    content_type="application/pdf",
    upload_to_assistant=False,
)
content = attachment.read_text()
```

!!! warning "Attachment file types"
    The Python node currently only supports reading the contents of the following file types:

    * Text files (this includes files like CSV, JSON etc)
    * PDF files
    * docx files

    Other file types can still be uploaded to assistants but the Python Node is not able to read the file contents using the `read_text()` method on the attachment.

## Template
Renders a [Jinja](https://jinja.palletsprojects.com/en/stable/templates/) template.

## Email
Send the input to the specified list of email addresses. This node acts as a passthrough, meaning the output will be identical to the input, allowing it to be used in a pipeline without affecting the conversation.

## Extract Structured Data
Extract structured data from the input. This node acts as a passthrough, meaning the output will be identical to the input, allowing it to be used in a pipeline without affecting the conversation.


## Update Participant Data
Extract structured data and save it as participant data.
